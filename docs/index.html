<!DOCTYPE html>
<html>
    <head>
        <title>MLC LLM | Home</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link rel="stylesheet"
              href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css"
              integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
              crossorigin="anonymous">
        <link rel="stylesheet"
              href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="/assets/css/main.css">
        <link rel="stylesheet" href="/assets/css/group.css">
        <!-- <link rel="stylesheet" href="/css/table.css">          -->
        <link rel="shortcut icon" href="/assets/img/logo/mlc-favicon.png">
        
    </head>
    <body>
        <div class="container">
            <!-- This is a bit nasty, but it basically says be a column first, and on larger screens be a spaced out row -->
            <div class="header d-flex
                        flex-column
                        flex-md-row justify-content-md-between">
              <a href="/" id="navtitle">
                  <img src="/assets/img/logo/mlc-logo-with-text-landscape.svg" height="70px"
                       alt="MLC" id="logo">
              </a>
              <ul id="topbar" class="nav nav-pills justify-content-center">
                    
                    

                        

                        
                        
                        

                      <li class="nav-item">
                         
                            <a class="nav-link active"
                               href="/">
                                Home
                            </a>
                         
                        </li>

                    

                        

                        
                        
                        

                      <li class="nav-item">
                         
                            <a class="nav-link "
                               href="/docs">
                                Docs
                            </a>
                         
                        </li>

                    

                        

                        
                        
                        

                      <li class="nav-item">
                         
                            <a class="nav-link "
                               href="https://github.com/mlc-ai/mlc-llm">
                                Github
                            </a>
                         
                        </li>

                    

                </ul>
            </div>

            

            
            <!-- Schedule  -->
            
                <h1 id="mlc-llm">MLC LLM</h1>

<p>Documentation: <a href="https://llm.mlc.ai/docs">https://llm.mlc.ai/docs</a></p>

<p><strong>M</strong>achine <strong>L</strong>earning <strong>C</strong>ompilation for <strong>L</strong>arge <strong>L</strong>anguage <strong>M</strong>odels (MLC LLM) is a high-performance universal deployment solution that allows native deployment of any large language models with native APIs with compiler acceleration. The mission of this project is to enable everyone to develop, optimize and deploy AI models natively on everyone’s devices with ML compilation techniques.</p>

<p align="center">
<img src="https://llm.mlc.ai/docs/_images/project-workflow.svg" height="300" />
</p>

<h2 id="installation">Installation</h2>

<p>MLC LLM is available via <a href="https://llm.mlc.ai/docs/install/mlc_llm.html#install-mlc-packages">pip</a>.
It is always recommended to install it in an isolated conda virtual environment.</p>

<p>To verify the installation, activate your virtual environment, run</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-c</span> <span class="s2">"import mlc_llm; print(mlc_llm.__path__)"</span>
</code></pre></div></div>

<p>You are expected to see the installation path of MLC LLM Python package.</p>

<h2 id="quick-start">Quick Start</h2>

<p>Please check out our documentation for the <a href="https://llm.mlc.ai/docs/get_started/quick_start.html">quick start</a>.</p>

<h2 id="introduction">Introduction</h2>

<p>Please check out our documentation for the <a href="https://llm.mlc.ai/docs/get_started/introduction.html">introduction</a>.</p>

<h2 id="links">Links</h2>

<ul>
  <li>You might want to check out our online public <a href="https://mlc.ai">Machine Learning Compilation course</a> for a systematic
walkthrough of our approaches.</li>
  <li><a href="https://webllm.mlc.ai/">WebLLM</a> is a companion project using MLC LLM’s WebGPU and WebAssembly backend.</li>
  <li><a href="https://websd.mlc.ai/">WebStableDiffusion</a> is a companion project for diffusion models with the WebGPU backend.</li>
</ul>

<h2 id="disclaimer">Disclaimer</h2>

<p>The pre-packaged demos are subject to the model License.</p>

            
        </div> <!-- /container -->

        <!-- Support retina images. -->
        <script type="text/javascript"
                src="/assets/js/srcset-polyfill.js"></script>
    </body>

</html>
